{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f654948a",
   "metadata": {},
   "source": [
    "# <center> Hito 3 - Prueba 1 \n",
    "## <center> Analisis de sentimientos en Twitter\n",
    "### <center> Adolfo Garc√≠a, Rodrigo Guerrero Vergara y Nicolas Sepulveda Lynch \n",
    "### <center> Generaci√≥n 46"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4a7c2c",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb5e0f7",
   "metadata": {},
   "source": [
    "# Hito 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd208dd",
   "metadata": {},
   "source": [
    "# Secci√≥n 1 - Aspectos Preeliminares"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd16b9c0",
   "metadata": {},
   "source": [
    "## 1.1 - Descripci√≥n del problema\n",
    "- Nos han pedido de an√°lisis de texto en la red social Twitter. En la cual se nos indica que como consultores independientes que creemos un modelo que obtenga  el mejor desempe√±o poisble para clasificar si un twitt es Negativo/Positivo el sentimiento de la persona que est√° creando el Twitt. Es decir, obtener el sentimiento asociado a cada \"twitt\". La manera que mediremos dicho deseempe√±o se realizar√° con el conjunto de datos sobre la cual no tendremos acceso, para evitar que los modelos aprendan informaci√≥n sobre el conjunto de validaci√≥n \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1995701",
   "metadata": {},
   "source": [
    "## 1.2 - Objetivos\n",
    "\n",
    "En esta primera prueba, nos indica que debemos cumplir con 5 requerimientos, los cuales son: \n",
    "\n",
    "1. Generar un __an√°lisis exploratorio__ sobre los datos contenidos en el DataFrame, considerando palabras m√°s comunes y distribuci√≥n de las clases en el vector objetivo.\n",
    "\n",
    "\n",
    "2. Preprocesamiento de Texto:\n",
    "\n",
    "        ‚óè Para trabajar adecuadamente con texto, debemos preprocesar y posteriormente representar cada oraci√≥n como un conjunto de caracter√≠sticas.\n",
    "        ‚óè Para preprocesar los tweets, debemos transformarlos a lower case. Un problema recurrente en el an√°lisis de texto es la alta ocurrencia de palabras comunes. Se recomienda eliminarlas mediante la declaraci√≥n de stopwords. Para generar la exclusi√≥n de stopwords, podemos utilizar la librer√≠a nltk (Natural Language ToolKit) y descargar los stopwords con la siguiente instrucci√≥n.\n",
    "    \n",
    "        import nltk\n",
    "        nltk.download('stopwords')\n",
    "    \n",
    "        ‚óè Puede refinar los atributos a capturar mediante el proceso de lemantizaci√≥n (la\n",
    "   reducci√≥n de variadas palabras con un tronco l√©xico com√∫n; ejemplo: Organizaci√≥n, Organiza, y Organizado presentan organi_ como tronco l√©xico en com√∫n) o Stemming (la reducci√≥n de una palabra a una expresi√≥n generalizable). Cabedestacar que √©sta √∫ltima carece de an√°lisis morfol√≥gico del lenguaje.\n",
    "\n",
    "        ‚óè Posterior a la refinaci√≥n y preprocesamiento de las palabras, podemos representar cada oraci√≥n en una matriz (o corpus) que permitir√° reflejar la cantidad de ocurrencias de ùëäùëñ palabra en un registro. Para ello, pueden hacer uso de las librer√≠as de preprocesamiento sklearn.feature_extraction.text.CountVectorizer o sklearn.feature_extraction.text.TfidfVectorizer. De esta manera, tendremos un conjunto de caracter√≠sticas es mediante la frecuencia de ocurrencia de una palabra o t√©rmino en el texto.\n",
    "    \n",
    "    \n",
    "3. Preparaci√≥n del vector objetivo y las matrices de entrenamiento y validaci√≥n:\n",
    "        ‚óè Nos interesa trabajar con dos tipos de emociones: positivas o negativas. Para ello deberemos recodificar  cada una de las clases en una de las dos emociones:\n",
    "\n",
    "                            'worry' Negativa\n",
    "                            'happiness' Positiva\n",
    "                            'sadness' Negativa\n",
    "                            'love' Positiva\n",
    "                            'surprise' Positiva\n",
    "                            'fun' Positiva\n",
    "                            'relief' Positiva\n",
    "                            'hate' Negativa\n",
    "                            'empty' Negativa\n",
    "                            'enthusiasm' Positiva\n",
    "                            'boredom' Negativa\n",
    "                            'anger' Negativa\n",
    "                            \n",
    "                            \n",
    "        ‚óè Si el tweet est√° asignado como *neutral*, clasif√≠quelo aleatoriamente entre positivo o negativo.\n",
    "\n",
    "4. Entrenamiento de modelos:\n",
    "        ‚óè En base a los modelos vistos en clase, implemente por lo menos 5. Para cada\n",
    "        uno de ellos justifique la elecci√≥n de hiper par√°metros. Si implementa\n",
    "        b√∫squeda de grilla para cada uno de ellos, defina el rango de valores a tomar\n",
    "        en cada hiper par√°metro.\n",
    "        ‚óè Reporte el desempe√±o de cada modelo en las muestras de entrenamiento y\n",
    "        validaci√≥n. Comente sobre la capacidad de generalizaci√≥n de cada uno de\n",
    "        ellos haciendo uso de los conceptos vistos en el curso.\n",
    "        \n",
    "        \n",
    "5. Seleccione los 2 mejores modelos, serialicelos y env√≠alos a evaluaci√≥n. Recuerde que el modelo serializado debe ser posterior al fit, para poder ejecutar __predict__ en los nuevos datos   \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5c6300",
   "metadata": {},
   "source": [
    "# 1.3 - Evaluaci√≥n\n",
    "\n",
    "La siguiente r√∫brica detalla los elementos que se evaluar√°n en el entregable final:\n",
    "\n",
    "1. Notebook (9 Puntos): El notebook debe ser un reporte con la estrategia anal√≠tica, explicando los siguientes puntos:\n",
    "    \n",
    "        ‚óè La definici√≥n de los requerimientos, la definici√≥n del vector objetivo, la definici√≥n de las m√©tricas a utilizar.(1 Puntos)\n",
    "        ‚óè Un an√°lisis exploratorio (univariado y gr√°fico). Como m√≠nimo, debe analizar el comportamiento del vector objetivo antes del preprocesamiento y posterior al procesamiento.(3 Puntos)\n",
    "        ‚óè La estrategia de preprocesamiento/feature engineering.(3 Puntos)\n",
    "        ‚óè La elecci√≥n de los algoritmos a implementar, as√≠ como sus hiper par√°metros. Un reporte sobre qu√© modelos se seleccionar√°n. (2 Puntos)\n",
    "        \n",
    "        \n",
    "        \n",
    "2. Modelos serializados (1 Puntos):\n",
    "    \n",
    "    \n",
    "     ‚óè Los modelos deben estar serializados con la siguiente nomenclatura:nombre_grupo-modelo-1 y nombre_grupo-modelo-2.\n",
    "     ‚óè La evaluaci√≥n de los modelos serializados se realizar√° en funci√≥n al desempe√±o predictivo\n",
    "      del modelo en un conjunto de datos externos.\n",
    "     ‚óè La primera instancia es evaluar los dos modelos enviados a competencia por el grupo, preservando el mejor                   modelo para la competencia con los otros grupos.\n",
    "     ‚óè El segundo paso es rankear seg√∫n el desempe√±o entre grupos.\n",
    "        \n",
    "        \n",
    "    El Grupo asociado debe obtener un m√≠nimo de 7 puntos para aprobar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0753bbcd",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346f96b6",
   "metadata": {},
   "source": [
    "# 1.4 - Implementaci√≥n de la soluci√≥n\n",
    "\n",
    "Para poder resolver el problema que se nos encomend√≥, asigaremos el siguiente manera de trabajar:\n",
    "\n",
    "‚óè Implementar las librer√≠as con funciones no nativas de python.\n",
    "\n",
    "‚óè Leer y analizar los datos asignados.\n",
    "\n",
    "‚óè Realizar un pre procesamiento de los datos mediante:\n",
    "\n",
    "    ‚óèInspecci√≥n gr√°fica de los datos.\n",
    "    \n",
    "    ‚óèDeterminar, reconvertir y eliminar datos perdidos de ser necesario.\n",
    "    \n",
    "    ‚óèRecodificar las variables y su contenido acorde a lo asociado.\n",
    "    \n",
    "    ‚óèReprocesar datos si encontramos pertinente al requerimiento origina seg√∫n los hallazgos en la data.\n",
    "    \n",
    "‚óèDividir la muestra para el modelamiento.\n",
    "\n",
    "‚óèConstruir distintos modelos de cada tipo, por medio de:\n",
    "\n",
    "    ‚óèObtenci√≥n de los modelos.\n",
    "    \n",
    "    ‚óèObtenci√≥n de m√©tricas de los modelos.\n",
    "    \n",
    "    ‚óèValidaciones cruzadas realizadas para el arrojo de los mejores h√≠perparametros asociados.\n",
    "    \n",
    "    ‚óèOptimizaci√≥n de los modelos.\n",
    "    \n",
    "    ‚óèElecci√≥n del mejor modelo de su tipo.\n",
    "    \n",
    "‚óèDebemos realizar comparaciones de los resultados por cada tipo de modelo.\n",
    "\n",
    "‚óèFinalmente, debemos seleccionar los modelos que serializaremos. Los 8 modelos seleccionados son:\n",
    "\n",
    "1-LogisticRegression\n",
    "\n",
    "2-MultinomialNB\n",
    "\n",
    "3-RandomForestClassifier\n",
    "\n",
    "4-AdaBoostClassifier \n",
    "\n",
    "5-GradientBoostingClassifier\n",
    " \n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b231f796",
   "metadata": {},
   "source": [
    "# 1.5 Criterios de optimizaci√≥n\n",
    "\n",
    "\n",
    "Si bien, como trabajadores independientes y en base a nuestra experiencia, estamos frente a un problema de clasificaci√≥n, el cual deberemos utilizar criterios de optimizaci√≥n que logren ajustarse en base a los resultados obtenidos en las m√©tricas de desempe√±os de los distintos modelos, mediante:\n",
    "\n",
    "   1 Criterios de optimizaci√≥n:\n",
    "   \n",
    "        ‚óè Aumentar la tasa de clases correcta predicha(Verdaderos Positivos).\n",
    "        \n",
    "        ‚óè Reducir los \"Falsos Positivos\" y \"Falsos Negativos\".\n",
    "        \n",
    "        \n",
    "   2 M√©tricas de desempe√±o:\n",
    "   \n",
    "   \n",
    "        ‚óè Para una evaluaci√≥n general del modelo se utilizar√° el Accuracy\n",
    "        \n",
    "        ‚óè Para la evaluaci√≥n de cada modelo:\n",
    "        \n",
    "            ‚óã Recall, Precision y F1-Score.\n",
    "            \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19097902",
   "metadata": {},
   "source": [
    "# 1.6 Aspectos a tener en consideraci√≥n\n",
    "\n",
    "En la prueba n¬∞1 se nos indica que la medici√≥n del desempe√±o que alcanzaremos ser√° evaluado con un conjunto de datos que como grupo no tendremos acceso, pero de igual manera debemos representar que tanto:\n",
    "\n",
    "‚óèLa cantidad de variables utilizadas para el entrenamiento como el nombre que \"CountVectorizer\" asignar√° a cada una de ellas son determinantes para que pueda desempe√±arse correctamente las prediciones que realizar√°n los modelos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c7c518",
   "metadata": {},
   "source": [
    "# Secci√≥n 2 - Aspectos Computaiconales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb7ec1e",
   "metadata": {},
   "source": [
    "## 2.1  - Descripci√≥n de las librerias a utilizar\n",
    "\n",
    "\n",
    "‚óè __Para el analisis exploratorio usaremos librerias para el analisis de datos como Matplotlib, Missingno, Pandas Profiling, en cambio para modelar y preprocesar usaremos distintos modulos de la libreria Sci-Kit Learn.__\n",
    "\n",
    "\n",
    "‚óè __Usaremos metricas para modelos clasificatorios, Curva ROC, F1-Score, Recall, Precision, de la libreria Sci-Kit Learn, modulo Metrics__\n",
    "\n",
    "Para lo antes comentado, y la correcta realizaci√≥n del requerimiento asociado a la prueba, realizaremos importar las librer√≠as no nativas de python para realizar analisis de datos, transformalos, construir los modelos predictivos solicitados, poder entrenar y validarlos. \n",
    "\n",
    "## Para ello, importaremos las siguientes librer√≠as y sus versiones: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7ca769",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Principales librer√≠as para la importaci√≥n, preprocesamiento y procesamiento de las bases de datos\n",
    "import pandas as pd #pandas Version: 1.4.2 \n",
    "import numpy as np # numpy Version: 1.21.5\n",
    "\n",
    "#Principales librer√≠as para visualizar gr√°ficos\n",
    "import seaborn as sns # seaborn Version:0.11.2\n",
    "import matplotlib.pyplot as plt # mmatplotlib Version: 3.5.1\n",
    "import missingno # missingno: 0.5.1\n",
    "import pandas_profiling #versi√≥n 2.4.0\n",
    "import preprocessor #versi√≥n 0.6.0\n",
    "\n",
    "# Librer√≠a para realizar stopwords en la data y poder limpiarla de mejor manera.\n",
    "import nltk # version 3.7 \n",
    "import re  # version 2022.9.13 \n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#importamos Random para clasificar entre positivo y negativo de forma aleatoria los tweets neutrales\n",
    "import random # version 3.8.13\n",
    "import pickle #version 0.7.5\n",
    "\n",
    "#Principales librer√≠as para modelamiento\n",
    "from sklearn.linear_model import LogisticRegression # Version:1.0.2\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV #Version: 1.0.2\n",
    "from sklearn.feature_extraction.text import CountVectorizer #Version: 1.0.2\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier #Version: 1.0.2\n",
    "from sklearn.tree import DecisionTreeClassifier  #Version: 1.0.2 \n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB, GaussianNB  #Version: 1.0.2\n",
    "from sklearn.decomposition import LatentDirichletAllocation #Version: 1.0.2\n",
    "from sklearn import pipeline\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "\n",
    "#Principales librer√≠as para m√©tricas de machine learning\n",
    "from sklearn.metrics import roc_curve,roc_auc_score,classification_report #Version: 1.0.2\n",
    "\n",
    "#Librer√≠a para evitar los avisos de advertencia, libre de avisos de deprecaci√≥n y FutureWarning\n",
    "import warnings #Versi√≥n 3.10.5\n",
    "warnings.filterwarnings('ignore', 'DeprecationWarning') #\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df236370",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4226ce30",
   "metadata": {},
   "source": [
    "## 2.2 - Descripci√≥n de las funciones a realizar \n",
    "\n",
    "Nosotros como empresa, contamos con nuestra propia librer√≠a llamada 'FuncionesZero\" llamada como funcz, la cual ser√° importada y debidamente documentada con sus respectivos 'Docstring'. \n",
    "\n",
    "**Importamos nuestras funciones llamadas 'funcz'**\n",
    "\n",
    "Se listan las principales funciones que utilizaremos nostoros para resolver el problema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601520f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import FuncionesZero as funcz # FuncionesZero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f0990a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"training_tweets.csv\").drop(columns='Unnamed: 0')  # Leemos nuestro archivo csv y borramos la columna Unnamed:0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3150fe3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df # Visualizamos como est√° compusto nuestro dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7c2620",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Quitamos URL, menciones, hashtags con nuestra funcion\n",
    "df['content_recod'] = df.apply(funcz.preproceso_tweet, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d95d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ejecutamos un head para observar los 5 primeros datos del dataframe \n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3a02db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#utilizamos la funcion preproceso_palabras, Esta funci√≥n tiene limpiar los tweets del dataframe, quitando URL,\n",
    "#hashtags, menciones por filas\n",
    "funcz.preproceso_palabras(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6174df32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ejecutamos un head para observar que se ejecut√≥ correctamente la funci√≥n y observamos los 5 primeros datos del dataframe \n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72df6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Visualizamos los sentimientos de cada tweet para recodificarlos en 2 categorias, P/N\n",
    "sns.countplot(df[\"sentiment\"]) \n",
    "plt.xticks(rotation=45);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b11711a",
   "metadata": {},
   "source": [
    "## La palabra previo a la recodificaci√≥n que m√°s predomina en la data son \"Neutral\" y \"Worry\", con sobre 6000 datos y lo siguen hapiness y sadness "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b489d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Recodificaciones de las variables a Positivo/Negativo\n",
    "positivas = ['happiness', 'love', 'surprise', 'fun', 'relief', 'enthusiasm']\n",
    "negativas = ['worry', 'sadness', 'hate', 'empty', 'boredom', 'anger']\n",
    "df['sentiment'] = df['sentiment'].replace(positivas, 'positiva')\n",
    "df['sentiment'] = df['sentiment'].replace(negativas, 'negativa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdc32bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizamos las nuevas columnas\n",
    "sns.countplot(df['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0dc4db",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Observaremos cuantos datos tiene cada observacion para proximamente recodificar\n",
    "df['sentiment'].value_counts() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d9b051",
   "metadata": {},
   "source": [
    "### Inicialmente en el desaf√≠o, un requerimiento impl√≠cito era el de distribuir aleatoriamente la cantidad de tuits con sentimientos \"neutrales\" tanto en tuits positivos  y negativos, pero posterior a una auditor√≠a con Daniel Zu√±iga, pudimos presentar una propuesta de optar por descartar los neutrales y as√≠ tener la certeza de que la data est√° clasificada de manera emp√≠rica. Al distribuir de manera azarosa, adem√°s de incurrir en un posible desbalance de clases, al momento de querer probar el modelo con nueva data, habr√≠a que realizar mismo reproceso de distribuci√≥n de neutrales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e56a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Realizamos la recodificaci√≥n ya justificada anterirmente\n",
    "df = df.drop(df.loc[df['sentiment']=='neutral'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cac7854",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(df['sentiment']) # Visualizacion de datos ya recodificados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8c427f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizamos un value counts para obtener la cantidad de valores negativos y positivos\n",
    "df['sentiment'].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218206c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observamos que no hay valores nulos\n",
    "missingno.matrix(df); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7971172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observamos que las 2 columnas son de tipo 'object'\n",
    "df.info() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddbcd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizamos la funci√≥n cuentaNaN para apreciar los valores perdidos\n",
    "funcz.cuenta_nan(df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac02f12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ejecutamos el df para apreciar que la funcion haya sido realizada correctamente \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c4aade",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca83498e",
   "metadata": {},
   "source": [
    "# Hito 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050f7344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instanciamos un objeto\n",
    "count_vectorizer = CountVectorizer(stop_words='english')\n",
    "# Implementamos los pasos fit y transform\n",
    "count_vectorizer_fit = count_vectorizer.fit_transform(df['content'])\n",
    "# Extraemos tokens (palabras)\n",
    "words = count_vectorizer.get_feature_names()\n",
    "# extraemos las frecuencias por palabras\n",
    "words_freq = count_vectorizer_fit.toarray().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edaa246",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creamos un nuevo objeto llamado df_cuentapalabras, buscando la frecuencia por palabra \n",
    "df_cuentaPalabras = pd.DataFrame({'Palabra': words, \n",
    "                                 'Frecuencia':words_freq}).sort_values(by=['Frecuencia'], ascending=False)\n",
    "\n",
    "\n",
    "df_cuentaPalabras = df_cuentaPalabras.head(100)\n",
    "\n",
    "plt.figure(figsize=(20, 25))\n",
    "\n",
    "ax = sns.barplot(x='Frecuencia', y='Palabra', data=df_cuentaPalabras)\n",
    "plt.title('100 Palabras mas frecuentes')\n",
    "\n",
    "#utilizamos la funci√≥n propuesta por el expositor:\n",
    "for p in ax.patches:\n",
    "    total = f'{p.get_width():,}'.replace(',','.')\n",
    "    x = p.get_x() + p.get_width() + 0.06\n",
    "    y = p.get_y() + p.get_height()/2\n",
    "    ax.annotate(total, (x, y))\n",
    "\n",
    "# mejoramos los m√°rgenes\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14e8968",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Ejecutamos la funci√≥n descrita como gr√°ficos_por_genero para apreciar la frecuencia de palabras \n",
    "funcz.graficos_por_genero(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2320e6",
   "metadata": {},
   "source": [
    "### Se observa del grafico anterior las palabras y sus frecuencias por cada clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b068d52a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Creamos el objeto posi, donde nos guardar√° las palabras positivas con la frecuencia de esta.\n",
    "posi = funcz.palabras_por_genero(df, 'positiva')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffea618",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Realizamos una inspecci√≥n visual del objeto creado\n",
    "posi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa01124e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos el objeto posi, donde nos guardar√° las palabras negativas con la frecuencia de esta.\n",
    "nega = funcz.palabras_por_genero(df, 'negativa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba10fb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Realizamos una inspecci√≥n visual del objeto creado\n",
    "nega"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d66148",
   "metadata": {},
   "source": [
    "### Observaremos cuantas palabras en comun tienen cada clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d56418",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "count=0\n",
    "for i in posi['Palabra']:\n",
    "    for j in nega['Palabra']:\n",
    "        if i == j:\n",
    "            count +=1\n",
    "count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88a86f5",
   "metadata": {},
   "source": [
    "### Por ende, hay 68 palabras en com√∫n que tiene cada clase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72b69dd",
   "metadata": {},
   "source": [
    "### Creamos dataframe para graficar diferencias "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2387b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pala = []\n",
    "frecu_pos = []\n",
    "frecu_neg = []\n",
    "for i in posi['Palabra']:\n",
    "    for j in nega['Palabra']:\n",
    "        if i == j:\n",
    "            pala.append(i)\n",
    "            frecu_pos.append(posi[posi['Palabra'] == i]['Frecuencia'].values[0])\n",
    "            frecu_neg.append(nega[nega['Palabra'] == i]['Frecuencia'].values[0])\n",
    "\n",
    "df_proban2 = pd.DataFrame(list(zip(pala, frecu_pos, frecu_neg)),\n",
    "               columns =['Palabra', 'Freq_positiva', 'Freq_negativa'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513b99d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Realizamos una observaci√≥n del nuevo objeto creado, mostrandonos la frecuencia de las palabras positivas y negativas que \n",
    "df_proban2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70b0fea",
   "metadata": {},
   "source": [
    "### Graficamos para mejor visualizaci√≥n de palabras con mayor diferencia/igualdad en frecuencias "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a1cb02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Seteamos un ploteo para observar y analizar la superposici√≥n de las palabras para posteriormente realizar una toma de decisi√≥n\n",
    "plt.figure(figsize=(10, 16))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(df_proban2['Freq_positiva'], df_proban2['Palabra'], 'o', alpha=.5, label=\"Positivas\")\n",
    "plt.plot(df_proban2['Freq_negativa'], df_proban2['Palabra'], '^', alpha=.5, label=\"Negativas\")\n",
    "plt.xlabel('Frequency')\n",
    "plt.title('Ocurrencia de atributos condicional a la clase')\n",
    "plt.legend();\n",
    "\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "store_diff = abs(df_proban2['Freq_positiva'] - df_proban2['Freq_negativa']) # calculamos diferencial\n",
    "\n",
    "plt.plot(store_diff, df_proban2['Palabra'], 'o', alpha=.8)\n",
    "plt.axvline(x = 200, color = 'red', alpha=.5)\n",
    "\n",
    "plt.title('Diferencial entre Positivas y Negativas')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8540303",
   "metadata": {},
   "source": [
    "### A continuaci√≥n revisamos un ultimo procesamineto de la data, para continuar con el modelaje:\n",
    "- Por una parte se observa que si descartamos las palabras que tienen frecuencias igual a 1, nos quedamos con aproximadamente 9000 palabras distintas. Optamos por mantenerlas en el dataframe.\n",
    "- Por otro lado, debemos decidir si descartar o no las palabras que tengan misma frecuencia en ambas clases, ya que estas no permitirian discriminar correctamente. Para determinar esto, usamos como criterio el grafico anterior, descartando aquellas palabras que se superponen en ambas clases. Estas ser√≠an:\n",
    "    - __man__\n",
    "    - __little__\n",
    "    - __come__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27aec43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ejecutamos un head para los 5 primeros datos\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7ee907",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Removemos las palabras se√±aladas anteriormente\n",
    "remove_palabras = lambda x: re.sub('man|little|come','',x)\n",
    "df['content_recod'] = df['content_recod'].map(remove_palabras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa078e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ejecutamos un head nuevamente para los 5 primeros datos y apreciar que se removieron correctamente las palabras con la expresi√≥n regular\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0407f6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ejecutamos un shape al df y nos quedaremos con 23549 tweets\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fec8f7",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9460df",
   "metadata": {},
   "source": [
    "# 3.2 Preparaci√≥n de la data a trabajar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2592b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#procedemos a definir el x e y, junto a los parametros de testeo y validaci√≥n\n",
    "x_vec = df['content_recod']\n",
    "y_vec = df['sentiment']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_vec, y_vec, test_size=.33, random_state=1213)\n",
    "\n",
    "print(\"Posterior a la divisi√≥n de la data del DF suministrado por el cliente recodificado para entrenar y validar es:\")\n",
    "\n",
    "print(\"x_train, x_test, y_train, y_test=train_test_split(x_vec,y_vec,test_size=.30,random_state=1213)))\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c3c235",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ejecutamos el x_train para oserrvar la largo y el dtype\n",
    "x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b6a985",
   "metadata": {},
   "source": [
    "## Definiremos la random state y el cross validation a utilizar en los 5 modelos propuestos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db6c4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs__cv = 2\n",
    "random_state=1213\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef28688c",
   "metadata": {},
   "source": [
    "# 3.3 Modelos a utilizar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7468a219",
   "metadata": {},
   "source": [
    "__Como grupo, decidimos utilizar los siguientes modelos clasificatorios para el problema que se nos plantea__\n",
    "\n",
    "‚óèLogisticRegression\n",
    "\n",
    "‚óèMultinomialNB\n",
    "\n",
    "‚óèRandomForestClassifier\n",
    "\n",
    "‚óèAdaBoostClassifier \n",
    "\n",
    "‚óèGradientBoostingClassifier "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7484d37c",
   "metadata": {},
   "source": [
    "# 3.3.1 Seteo del Pipeline e Hiperp√°rametros en los modelos que utilizaremos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4706f682",
   "metadata": {},
   "source": [
    "## 3.3.1.1 LogisticRegression \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949d62d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Procedemos a la construcci√≥n del pipeline para el modelo Logistic Regression\n",
    "nombre_del_modelo= \"LogisticRegression\"\n",
    "#pipeline_lr = pipeline.Pipeline([('cv',CountVectorizer()),'lr',LogisticRegression()])\n",
    "#pipeline_lr\n",
    "\n",
    "\n",
    "pipeline_model_lr = pipeline.Pipeline([\n",
    "                ('count_vectorizer', CountVectorizer(stop_words='english')),\n",
    "                ('logistic', LogisticRegression())])\n",
    "\n",
    "pipeline_model_lr\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aadcec9",
   "metadata": {},
   "source": [
    "__Creamos el Pipeline con el CountVectorizer para construir la matriz de las palabras de entrenamiento y el modelo 3.3.1.1 Logistic Regression.__ \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0054033",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Posterior al pipeline, creamos el diccionario con los hiperpar√°metros tanto de countvectorizer \n",
    "#como del modelo LogisticRegression en el cual utilizaremos el Gridsearch\n",
    "\n",
    "parametros_lr= {'logistic__random_state':[random_state],'logistic__penalty':['l2','none'],'logistic__C':[0.5,1,5],\n",
    "                'logistic__class_weight':['balanced',None],'logistic__solver':['newton-cg','lbfgs'],}\n",
    "            \n",
    "#y procedemos a printear los par√°metros del modelo Logistic Regresison\n",
    "\n",
    "print(f\"{parametros_lr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f908065",
   "metadata": {},
   "source": [
    "__Donde los siguientes hiperpar√°metros ser√°n definidos:__ \n",
    "\n",
    "‚óèlogistic_random_state: es la semilla pseudoaleatoria que hemos escogido\n",
    "\n",
    "‚óèlogistic_C: Es el inverso de la fuerza de regularizaci√≥n, utilizaremos valores bajos y sobre el defecto\n",
    "\n",
    "‚óèlogistic_class_weight: Es el peso de las clases, donde None es el que viene por defecto\n",
    "\n",
    "‚óèlogistic_solver: Es el algoritmo de optimizaci√≥n, donde utilizaremos \"newton-cg\" y \"lbfgs\"\n",
    "\n",
    "‚óèlogistic_penalty: Es la norma de menalizaci√≥n, donde se utilizar√° \"l2\" y \"none\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfc8571",
   "metadata": {},
   "source": [
    "## 3.3.1.2 MultinomialNB\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4588a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Procedemos a crear el pipeline con Count Vectorizer para la construcci√≥n del modelo MultinomialNB\n",
    "nombre_del_modelo= 'MultinomialNB'\n",
    "pipeline_model_mnb = pipeline.Pipeline([\n",
    "                ('count_vectorizer', CountVectorizer(stop_words='english')),\n",
    "                ('multinb', MultinomialNB())])\n",
    "\n",
    "pipeline_model_mnb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6509c29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Posterior al pipeline, creamos el diccionario con los hiperpar√°metros tanto de countvectorizer \n",
    "#como del modelo MultinomialNB en el cual utilizaremos el Gridsearch\n",
    "parametros_mnb= {'multinb__alpha':[0.001,0.01,0.1,1],}\n",
    "\n",
    "print(f\"{parametros_mnb}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a88def8",
   "metadata": {},
   "source": [
    "__Donde los siguientes hiperpar√°metros ser√°n definidos:__ \n",
    "\n",
    "‚óèmultinb__alpha: Es el ajuste al modelo de forma aditiva, en el cual utilizaremos el rango de [0.001,0.001,0.01,0.1,1] como hiperpar√°metro de este modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1247460",
   "metadata": {},
   "source": [
    "## 3.3.1.3 RandomForestClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8620bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Procedemos a crear el pipeline con Count Vectorizer para la construcci√≥n del modelo RandomForestClassifier\n",
    "nombre_del_modelo= 'RandomForestClassifier'\n",
    "\n",
    "pipeline_model_rfc = pipeline.Pipeline([\n",
    "                ('count_vectorizer', CountVectorizer(stop_words='english')),\n",
    "                ('rfc', RandomForestClassifier())])\n",
    "\n",
    "pipeline_model_rfc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c81f3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Posterior al pipeline, creamos el diccionario con los hiperpar√°metros tanto de countvectorizer \n",
    "#como del modelo RandomForestClassifier en el cual utilizaremos el Gridsearch\n",
    "\n",
    "parametros_rfc= {'rfc__random_state':[random_state],'rfc__n_estimators':list(np.linspace(10,200,5,dtype=\"int\"))\n",
    "                 ,'rfc__oob_score':[False,True],'rfc__max_features':['log2','sqrt']}\n",
    "\n",
    "print(f\"{parametros_rfc}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4bf7e0",
   "metadata": {},
   "source": [
    "__Donde los siguientes hiperpar√°metros ser√°n definidos:__ \n",
    "\n",
    "‚óèrfc__random_state: Es la semilla pseudoaleatoria que hemos escogido\n",
    "\n",
    "‚óèrfc__n_estimators: Es la cantidad de arboles que generaremos. Esto tiene como finalidad encontrar un n√∫mero iniciar para posteriormente, ajustar la lista al n√∫mero cercano para volver a ejecutarlo\n",
    "\n",
    "‚óèrfc__oob_score: Indicaremos si utilizaremos 'out of bag', el cual utilizaremos False y True\n",
    "\n",
    "‚óèrfc__max_features: Es el n√∫mero de atributos que ser√°n considerados para la division de los datos, se utilizar√° \"None\",\"log2\" y \"sqrt\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee0ba79",
   "metadata": {},
   "source": [
    "## 3.3.1.4 AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48bcea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Procedemos a crear el pipeline con Count Vectorizer para la construcci√≥n del modelo AdaBoostClassifier\n",
    "nombre_del_modelo= 'AdaBoostClassifier'\n",
    "\n",
    "pipeline_model_abc = pipeline.Pipeline([\n",
    "                ('count_vectorizer', CountVectorizer(stop_words='english')),\n",
    "                ('abc', AdaBoostClassifier())])\n",
    "\n",
    "pipeline_model_abc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f0ff02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Posterior al pipeline, creamos el diccionario con los hiperpar√°metros tanto de countvectorizer \n",
    "#como del modelo AdaBoostClassifier en el cual utilizaremos el Gridsearch\n",
    "\n",
    "parametros_abc = {'abc__random_state':[random_state],'abc__n_estimators':[50,250,500,100,1500,2000],'abc__learning_rate':[0.01,0.5,0.1,1,1.5,2],}\n",
    "\n",
    "print(f\"{parametros_abc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0212030b",
   "metadata": {},
   "source": [
    "__Donde los siguientes hiperpar√°metros ser√°n definidos:__ \n",
    "\n",
    "‚óèabc__random_state: Es la semilla pseudoaleatoria que hemos escogido\n",
    "\n",
    "‚óèabc__n_estimators:Es la cantidad de estimadores que utilizar√° dicho AdaBoost, utilizaremos el intervalo de [50,250,500,100,1500,2000].\n",
    "\n",
    "‚óèabc__learning_rate: Es la tasa de aprendizaje del modelo, utilizaremos el intervalo de [0.01,0.5,0.1,1,1.5,2] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4b1231",
   "metadata": {},
   "source": [
    "## 3.3.1.5 GradientBoostingClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91430150",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Procedemos a crear el pipeline con Count Vectorizer para la construcci√≥n del modelo GradientBoostingClassifier \n",
    "nombre_del_modelo= 'GradientBoostClassifier'\n",
    "\n",
    "pipeline_model_gbc = pipeline.Pipeline([\n",
    "                ('count_vectorizer', CountVectorizer(stop_words='english')),\n",
    "                ('gbc', GradientBoostingClassifier())])\n",
    "\n",
    "pipeline_model_gbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe2b914",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Posterior al pipeline, creamos el diccionario con los hiperpar√°metros tanto de countvectorizer \n",
    "#como del modelo GradientBoostingClassifier en el cual utilizaremos el Gridsearch\n",
    "parametros_gbc = {'gbc__random_state':[random_state],'gbc__loss':['deviance','exponential'],'gbc__learning_rate':[0.01,0.1,1,],'gbc__n_estimators':[100,1000,10000],'gbc__subsample':[0.1,0.5,1]}\n",
    "print(f\"{parametros_gbc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de002e2d",
   "metadata": {},
   "source": [
    "__Donde los siguientes hiperpar√°metros ser√°n definidos:__ \n",
    "\n",
    "‚óègbc_random_state: Es la semilla pseudoaleatoria que hemos escogido\n",
    "\n",
    "‚óègbc__loss: Es la funcion de perdida utilizadas.\n",
    "    \n",
    "‚óègbc__learning_rate: Es la tasa de aprendizaje del modelo, utilizaremos el intervalo de [0.01,0.05,0.1,1,]\n",
    "    \n",
    "‚óègbc__n_estimators:Es la cantidad de estimadores que utilizar√° dicho BoostingClassifier, se utilizar√° 100 y 1000.\n",
    "\n",
    "‚óègbc__subsample: Es la fracci√≥n de muestra para entrenar cada iteraci√≥n, utilizaremos el intervalo de [0.1,0.5,0.8,0.9,1].\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4daf9a2",
   "metadata": {},
   "source": [
    "## Ahora procedemos a realizar las validaciones cruzadas mediante GridSearch(GS) para cada modelo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf01cdd2",
   "metadata": {},
   "source": [
    "## Se utilizar√° la librer√≠a pickle para instanciar los objetos serializados por GS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323e6221",
   "metadata": {},
   "source": [
    "## 3.3.1 LogisticRegression-GridSearch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537c2372",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Procedemos a crear la busqueda de grilla (GS) para el modelo LogisticRegression y los par√°metros correspondientes.\n",
    "nombre_del_modelo= 'LogisticRegression'\n",
    "print(f\"Creamos un GS con una cantidad de {gs__cv} cross validations en base al pipeline \\ny sus respectivos hiperpar√°metros del modelo LogisticRegression\")\n",
    "\n",
    "gs_lr = GridSearchCV(pipeline_model_lr,parametros_lr,n_jobs=-1,verbose=1,cv=gs__cv)\n",
    "\n",
    "gs_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6c1d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Procedemos a fitear el modelo ya aplicada la busqueda de grilla con las 2 cross validations\n",
    "gs_lr.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4f24ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ejecutamos el predict para las m√©tricas\n",
    "\n",
    "y_hat_lr=gs_lr.predict(x_test)\n",
    "\n",
    "print(\"Ejecutamos las predicciones sobre las m√©tricas \\ny_hat_lr=gs_lr.predict(x_test)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8d6e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#procedemos a printear los mejores hiperpar√°metros del modelo \n",
    "print(f\"Procedemos a mostrar los hiperpar√°metros {nombre_del_modelo}\" )\n",
    "\n",
    "gs_lr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18c8196",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Procedemos a realizar un classification report para el y_test y el y_hat del modelo LogisticRegression\n",
    "print(classification_report(y_test,y_hat_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ad30e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Serializando el modelo {nombre_del_modelo} en el archivo \\n 'prueba_1_hito_3_{nombre_del_modelo}.sav'\" )\n",
    "pickle.dump(gs_lr,open('prueba_1_hito_3_'+nombre_del_modelo+'.sav','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b51c46",
   "metadata": {},
   "source": [
    "## 3.3.2 MultinomialNB-GridSearch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf84fd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Procedemos a crear la busqueda de grilla (GS) para el modelo MultinomialNB y los par√°metros correspondientes.\n",
    "nombre_del_modelo= 'MultinomialNB'\n",
    "print(f\"Creamos un GS con una cantidad de {gs__cv} cross validations en base al pipeline \\ny sus respectivos hiperpar√°metros del modelo MultinomialNB\")\n",
    "\n",
    "gs_mnb = GridSearchCV(pipeline_model_mnb,parametros_mnb,n_jobs=-2,verbose=2,cv=gs__cv)\n",
    "\n",
    "gs_mnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0af98ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Procedemos a fitear el modelo ya aplicada la busqueda de grilla con las 2 cross validations\n",
    "gs_mnb.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9da98a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ejecutamos el predict para las m√©tricas\n",
    "\n",
    "y_hat_mnb=gs_mnb.predict(x_test)\n",
    "\n",
    "print(\"Ejecutamos las predicciones sobre las m√©tricas \\ny_hat_mnb=gs_mnb.predict(x_test)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c910e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#procedemos a printear los mejores hiperpar√°metros del modelo \n",
    "print(f\"Procedemos a mostrar los hiperpar√°metros {nombre_del_modelo}\" )\n",
    "\n",
    "gs_mnb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6d99a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Procedemos a realizar un classification report para el y_test y el y_hat del modelo MultinomialNB\n",
    "print(classification_report(y_test,y_hat_mnb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ee7582",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Procedemos a serializar el objeto del mejor resultado\n",
    "\n",
    "print(f\"Serializando el modelo {nombre_del_modelo} en el archivo \\n 'prueba_1_hito_3_{nombre_del_modelo}.sav'\" )\n",
    "pickle.dump(gs_mnb,open('prueba_1_hito_3_'+nombre_del_modelo+'.sav','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fba982",
   "metadata": {},
   "source": [
    "## 3.3.3 RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77496407",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Procedemos a crear la busqueda de grilla (GS) para el modelo RandomForestClassifier y los par√°metros correspondientes.\n",
    "nombre_del_modelo= 'RandomForestClassifier'\n",
    "print(f\"Creamos un GS con una cantidad de {gs__cv} cross validations en base al pipeline \\ny sus respectivos hiperpar√°metros del modelo RandomForestClassifier\")\n",
    "\n",
    "gs_rfc = GridSearchCV(pipeline_model_rfc,parametros_rfc, n_jobs=-1,verbose=1,cv=gs__cv)\n",
    "\n",
    "gs_rfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc342fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Procedemos a fitear el modelo ya aplicada la busqueda de grilla con las 2 cross validations\n",
    "gs_rfc.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb55296",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ejecutamos el predict para las m√©tricas\n",
    "\n",
    "y_hat_rfc=gs_rfc.predict(x_test)\n",
    "\n",
    "print(\"Ejecutamos las predicciones sobre las m√©tricas \\ny_hat_rfc=gs_rfc.predict(x_test)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10657993",
   "metadata": {},
   "outputs": [],
   "source": [
    "#procedemos a printear los mejores hiperpar√°metros del modelo \n",
    "print(f\"Procedemos a mostrar los hiperpar√°metros {nombre_del_modelo}\" )\n",
    "\n",
    "gs_rfc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7601d92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Procedemos a realizar un classification reprot para el y_test y el y_hat del modelo RandomForestClassifier\n",
    "print(classification_report(y_test,y_hat_rfc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46c30c2",
   "metadata": {},
   "source": [
    "## 3.3.4 AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a205a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Procedemos a crear la busqueda de grilla (GS) para el modelo AdaBoostClassifier y los par√°metros correspondientes.\n",
    "nombre_del_modelo= 'AdaBoostClassifier'\n",
    "print(f\"Creamos un GS con una cantidad de {gs__cv} cross validations en base al pipeline \\ny sus respectivos hiperpar√°metros del modelo AdaBoostClassifier\")\n",
    "\n",
    "gs_abc = GridSearchCV(pipeline_model_abc,parametros_abc, n_jobs=-1,verbose=1,cv=gs__cv)\n",
    "\n",
    "gs_abc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74cca9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Procedemos a fitear el modelo ya aplicada la busqueda de grilla con las 2 cross validations\n",
    "gs_abc.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1abb834",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ejecutamos el predict para las m√©tricas\n",
    "\n",
    "y_hat_abc=gs_abc.predict(x_test)\n",
    "\n",
    "print(\"Ejecutamos las predicciones sobre las m√©tricas \\ny_hat_abc=gs_abc.predict(x_test)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cb050a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#procedemos a printear los mejores hiperpar√°metros del modelo \n",
    "print(f\"Procedemos a mostrar los hiperpar√°metros {nombre_del_modelo}\" )\n",
    "\n",
    "gs_abc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5068aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Procedemos a realizar un classification reprot para el y_test y el y_hat del modelo AdaBoostClassifier\n",
    "print(classification_report(y_test,y_hat_abc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc4eaeb",
   "metadata": {},
   "source": [
    "## 3.3.5 GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4364335f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Procedemos a crear la busqueda de grilla (GS) para el modelo GradientBoostingClassifier y los par√°metros correspondientes.\n",
    "nombre_del_modelo= 'GradientBoostingClassifier'\n",
    "print(f\"Creamos un GS con una cantidad de {gs__cv} cross validations en base al pipeline \\ny sus respectivos hiperpar√°metros del modelo GradientBoostingClassifier\")\n",
    "\n",
    "gs_gbc = GridSearchCV(pipeline_model_gbc,parametros_gbc, n_jobs=-1,verbose=1,cv=gs__cv)\n",
    "\n",
    "gs_gbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de38e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Procedemos a fitear el modelo ya aplicada la busqueda de grilla con las 2 cross validations\n",
    "gs_gbc.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea99e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ejecutamos el predict para las m√©tricas\n",
    "\n",
    "y_hat_gbc=gs_gbc.predict(x_test)\n",
    "\n",
    "print(\"Ejecutamos las predicciones sobre las m√©tricas \\ny_hat_rfc=gs_gbc.predict(x_test)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31c1a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#procedemos a printear los mejores hiperpar√°metros del modelo \n",
    "print(f\"Procedemos a mostrar los hiperpar√°metros {nombre_del_modelo}\" )\n",
    "\n",
    "gs_gbc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06c25ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Procedemos a realizar un classification reprot para el y_test y el y_hat del modelo GradientBoostingClassifier\n",
    "print(classification_report(y_test,y_hat_gbc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b4fcb8",
   "metadata": {},
   "source": [
    "__Despues de modelar algunos modelos y evaluar las metricas para cada uno de ellos logramos encontrar por la metrica F1-Score weighted average cuales son los mejores modelos en orden de F1-Score, con sus respectivos hiper parametros mostrados en chunks anteriores, estos son:__\n",
    "\n",
    "<li> 1. Logistic Regression,  F1-Score weighted average: 0.72, </li>\n",
    "    <li> 2. Multinomial Naive-Bayes, F1-Score weighted average : 0.72 </li>\n",
    "                <li> 3. Random Forest Classifier, F1-Score weighted average: 0.71 </li>\n",
    "                    <li> 4. AdaBoost Classifier, F1-Score weighted average : 0.72 </li>\n",
    "        \t\t<li> 5. Gradient Boosting Classifier, F1-Score weighted average: 0.72</li>\n",
    "\n",
    "                        \n",
    "__Estos son los mejores modelos probados, en orden de mejor a peor, considerando el costo computacional ser√≠an__:\n",
    "\n",
    "__1:Logistic Regression__\n",
    "\n",
    "__2:Multinomial Naive-Bayes__\n",
    "\n",
    "__3:AdaBoost Classifier__\n",
    "\n",
    "__4:Gradient Boosting Classifier__\n",
    "\n",
    "__5:Random Forest Classifier__\n",
    "\n",
    "\n",
    "Por ende, ya serializados los dos mejores modelos podemos concluir que tanto el de Logistic Regression junto a Multinomial Naive-Bayes son los que entregan unas mejores m√©tricas versus el costo computacional, prediciendo ambos modelos un 72% de  weight average, el cual est√° situado un 22% sobre un modelo que prediga al azar (50%). Por ende, el problema propuesto por nuestro cliente y desarrollado en base a nuestro conocimiento satisfacer√≠a los requerimientos y damos termino al caso de analisis de sentimientos de Twitter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80130062",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
